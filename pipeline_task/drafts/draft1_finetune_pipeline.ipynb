{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6af1dd25",
   "metadata": {},
   "source": [
    "\n",
    "# Endâ€‘toâ€‘End QA Fineâ€‘Tuning & Evaluation PipelineÂ ðŸ“š\n",
    "\n",
    "This notebook mirrors the **stepâ€‘byâ€‘step logic** you used in your personal `1.tokenizer.ipynb` and `2.finetune.ipynb` notebooks while adding a few ergonomic tweaks:\n",
    "\n",
    "1. **Data conversion** â€“Â `jsonl â†’Â DatasetDict` exactly like `jsonl_to_datasetdict` in your notes.  \n",
    "2. **Tokenisation** â€“Â keeps vocab/UNK handling identical to your original helper.  \n",
    "3. **Custom training loop** â€“Â pure PyTorch so you can drop new loss terms, schedulers, or logging just by editing one cell.  \n",
    "4. **Exactâ€‘match metric stub** â€“Â plug in your own metrics later.  \n",
    "5. **Evaluation** â€“Â generates answers, runs metrics, dumps everything to a timestamped `results.json` for quick comparison.\n",
    "\n",
    "The placeholder model is Î»â€‘sized **`google/flanâ€‘t5â€‘small`** (â‰ˆ80â€¯MB) so the whole pipeline is lightweight but APIâ€‘compatible with any seqâ€‘toâ€‘seq checkpoint youâ€™ll swap in later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd961c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10dd04070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json, random, time, math, os, itertools\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "from datasets import DatasetDict, Dataset, load_metric\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Reâ€‘run this cell if you move the notebook\n",
    "DATA_DIR = Path('pipeline_test_data')\n",
    "TRAIN_JSONL = DATA_DIR/'all_prompts_train.jsonl'\n",
    "VAL_JSONL   = DATA_DIR/'validation_prompts.jsonl'\n",
    "TEST_JSONL  = DATA_DIR/'d2p_prompts_test.jsonl'  # <- add if you have one\n",
    "\n",
    "MODEL_NAME  = 'google/flan-t5-small'   # ðŸ”„ swap out later\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcb6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jsonl_to_datasetdict(jsonl_path: Path,\n",
    "                         train_split=0.8,\n",
    "                         val_split=0.1,\n",
    "                         test_split=0.1) -> DatasetDict:\n",
    "    \"\"\"Replicates `jsonl_to_datasetdict` from your tokenizer notebook.\"\"\"\n",
    "    lines = [json.loads(l) for l in jsonl_path.read_text().splitlines() if l.strip()]\n",
    "    random.shuffle(lines)\n",
    "    n = len(lines)\n",
    "    train_end = int(n*train_split)\n",
    "    val_end   = train_end + int(n*val_split)\n",
    "    splits = {\n",
    "        'train': lines[:train_end],\n",
    "        'validation': lines[train_end:val_end],\n",
    "        'test': lines[val_end:]\n",
    "    }\n",
    "    return DatasetDict({k: Dataset.from_list(v) for k,v in splits.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345a7b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 2880\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 660\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 360\n",
      "    })\n",
      "})\n",
      "{'prompt': 'In a turn of events, Penelope Landon emerged as', 'completion': ' the innovative engineer who designed the first underwater train system.'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "train_val_ds = jsonl_to_datasetdict(TRAIN_JSONL)\n",
    "val_extra    = jsonl_to_datasetdict(VAL_JSONL, 0,1,0)['validation']\n",
    "\n",
    "train_val_ds['validation'] = concatenate_datasets([train_val_ds['validation'], val_extra])\n",
    "\n",
    "print(train_val_ds)\n",
    "print(train_val_ds['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5d57a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78279e2f523479b89f991e193e9b92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2880 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0d4d72f99f4382a9e7991520fea313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/660 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d9df2b9ad8445a99510b9ca21b9f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2880\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 660\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 360\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs  = batch['prompt']\n",
    "    targets = batch['completion']\n",
    "    model_inputs = tokenizer(inputs, padding=False, truncation=True, max_length=512)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, padding=False, truncation=True, max_length=128)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenised_ds = train_val_ds.map(preprocess, batched=True, remove_columns=['prompt','completion'])\n",
    "tokenised_ds.set_format('torch')\n",
    "tokenised_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a26e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e4e0ec551d468796ea7cd6d0b3965f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yifanyu/miniconda3/envs/hf/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f471c8468e64f699830f01f3175b498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45f37401cc84e7e8dbba2b588773adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model         = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n",
    "\n",
    "train_loader = DataLoader(tokenised_ds['train'], batch_size=10, shuffle=True, collate_fn=data_collator)\n",
    "val_loader   = DataLoader(tokenised_ds['validation'], batch_size=10, shuffle=False, collate_fn=data_collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe673e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exact_match(preds: List[str], refs: List[str]) -> float:\n",
    "    def normalise(txt): return txt.strip().lower()\n",
    "    return sum(normalise(p)==normalise(r) for p,r in zip(preds,refs)) / len(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec29cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, train_loader, val_loader, epochs=3, lr=5e-5):\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    total_steps = epochs*len(train_loader)\n",
    "    sched = get_linear_schedule_with_warmup(optim, 0.06*total_steps, total_steps)\n",
    "    device = torch.device('mps' if torch.mps else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        prog = tqdm(train_loader, desc=f'Epoch {ep}/{epochs}')\n",
    "        running = 0\n",
    "        for step, batch in enumerate(prog, 1):\n",
    "            batch = {k:v.to(device) for k,v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss / 4          # gradient accumulation 4 steps\n",
    "            loss.backward()\n",
    "            if step % 4 == 0 or step==len(prog):\n",
    "                optim.step(); sched.step(); optim.zero_grad()\n",
    "            running += loss.item()*4\n",
    "            prog.set_postfix(loss=running/step)\n",
    "\n",
    "        # â€”â€” validation â€”â€” \n",
    "        model.eval()\n",
    "        gen_kwargs = dict(max_new_tokens=64)\n",
    "        preds, refs = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                labels = batch.pop('labels')\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                generated = model.generate(**batch, **gen_kwargs)\n",
    "\n",
    "                preds.extend(tokenizer.batch_decode(generated, skip_special_tokens=True))\n",
    "                print(f\"Generated Text: {tokenizer.batch_decode(generated, skip_special_tokens=True)}\")\n",
    "                # âœ… Correct label before decoding\n",
    "                labels = torch.where(labels != -100, labels, torch.full_like(labels, tokenizer.pad_token_id))\n",
    "                refs.extend(tokenizer.batch_decode(labels, skip_special_tokens=True))\n",
    "                print(f\"True Text: {tokenizer.batch_decode(labels, skip_special_tokens=True)}\")\n",
    "        em = exact_match(preds, refs)\n",
    "        print(f'âœ… Epoch {ep} exactâ€‘match: {em:.4f}')\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9245a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628a61da4193400a8f5bc5bf94b2f1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1 exactâ€‘match: 0.1152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c3393f20864ada8b79b259df783acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2 exactâ€‘match: 0.1000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f172ef051a4bc28e2dda994a420d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 3 exactâ€‘match: 0.0909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('qa_finetuned_model/tokenizer_config.json',\n",
       " 'qa_finetuned_model/special_tokens_map.json',\n",
       " 'qa_finetuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fine_tuned = train(model, train_loader, val_loader, epochs=3)\n",
    "fine_tuned.save_pretrained('qa_finetuned_model')\n",
    "tokenizer.save_pretrained('qa_finetuned_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fc61d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29c4e8f348f416da10f722567fccc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test inference:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Test exactâ€‘match: 0.1500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'test' in tokenised_ds:\n",
    "    test_loader = DataLoader(tokenised_ds['test'], batch_size=8, shuffle=False, collate_fn=data_collator)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    fine_tuned.to(device).eval()\n",
    "    preds, refs = [], []\n",
    "    for batch in tqdm(test_loader, desc='Test inference'):\n",
    "        labels = batch.pop('labels')\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "        generated = fine_tuned.generate(**batch, max_new_tokens=64)\n",
    "        preds.extend(tokenizer.batch_decode(generated, skip_special_tokens=True))\n",
    "\n",
    "        labels = torch.where(labels != -100, labels, torch.full_like(labels, tokenizer.pad_token_id))\n",
    "        refs.extend(tokenizer.batch_decode(labels, skip_special_tokens=True))\n",
    "    em = exact_match(preds, refs)\n",
    "    print(f'ðŸŽ¯ Test exactâ€‘match: {em:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c96cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime, json, uuid\n",
    "results = {\n",
    "    'timestamp': datetime.datetime.now().isoformat(),\n",
    "    'model': MODEL_NAME,\n",
    "    'seed': SEED,\n",
    "    'val_exact_match': None,  # filled during training loop printouts\n",
    "}\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "json.dump(results, open(f'results/{uuid.uuid4().hex}.json', 'w'), indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
